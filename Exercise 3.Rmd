---
title: "Exercise 3"
output: github_document
---

By Hana Krijestorac, David Garrett, and Elliot Chau

Problem 1
================
Model selection and regularization: green buildlings
----------------
```{r part1, include=FALSE}
library(caret)
library(gamlr)
greenbuildings <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/greenbuildings.csv")
str(greenbuildings)

gbPrice = greenbuildings

# Descriptive Statistics and data Preprocessing
library(skimr)
library(knitr)
skim(greenbuildings) %>% skimr::kable()

# Check Missing Values
sum(is.na(greenbuildings))
table(is.na(greenbuildings))
prop.table(table(is.na(greenbuildings)))
# Only .04% of total data is missing
colMeans(is.na(greenbuildings))
# .937% or the empl_gr data is missing from the dataset

#Check Correlation of empl_gr with other variables to see if it is MAR or MNAR
library(corrr)
library(ggplot2)
library(dplyr)
empl_gr_Check <- greenbuildings %>%
  correlate() %>%
  focus(empl_gr)

empl_gr_Check

empl_gr_Check %>% 
  mutate(rowname = factor(rowname, levels = rowname[order(empl_gr)])) %>%  # Order by correlation strength
  ggplot(aes(x = rowname, y = empl_gr)) +
  geom_bar(stat = "identity") +
  ylab("Correlation with empl_gr") +
  xlab("Variable") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Imputation of missing data for emp_gl using MICE
# Assumption: missing data is MAR and therefore all values that are missing can be explained by the data we already have
# Statistical reasoning: Deleting NA data or simply replacing with the mean or mode can bias our model
# it is unlikely that the missing values are random, and it is correlated with other variables of interest, therefore we can predict the missing values
library(mice)
md.pattern(greenbuildings)
mice_imputes = mice(greenbuildings, m=5, maxit = 50, seed = 100)
mice_imputes$method
mice_imputes

# Red line is imputed data, blue line is original; due to similarity, we can assume that the missing values were MAR
densityplot(mice_imputes)

# Choose final model
gb_impute = complete(mice_imputes,5)
gb_impute

View(gb_impute)

# Check for missing values, and look at summary statistics for the imputed data set
skim(gb_impute) %>% skimr::kable()

# Correlation graphs for the greenbuildings dataset
# Not Necessary, but could be useful for visualization?? 
library(GGally)
ggpairs(data = gb_impute, columns =1:3, title = "Green Buildings Correlation Plot")
ggpairs(data = gb_impute,columns =3:8, title = "Green Buildings Correlation Plot 2")

# Use new data set to check correlation of rent with other variables
rent_Check <- gb_impute %>%
  correlate() %>%
  focus(Rent)

rent_Check

as.matrix(rent_Check)

rent_Check %>% 
  mutate(rowname = factor(rowname, levels = rowname[order(Rent)])) %>%  # Order by correlation strength
  ggplot(aes(x = rowname, y = Rent)) +
  geom_bar(stat = "identity") +
  ylab("Correlation with Rent") +
  xlab("Variable") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#########
# Number of cores
library(foreach)
library(doMC)

# Register Cores
registerDoMC(2)
#########

# Forward Selection Model
gb_lm0 = lm(Rent ~ 1, data= gb_impute)
gb_lm_forward = step(gb_lm0, direction='forward',
                  scope=~(cluster + size + empl_gr + leasing_rate + stories + age + renovated + 
                          class_a + class_b + LEED + Energystar + green_rating + net + amenities +
                          cd_total_07 + hd_total07 + total_dd_07 + Precipitation+ Gas_Costs + Electricity_Costs
                          + cluster_rent)^2)
# AIC_gb_lm_forward = 34768.95

# Step Function
# Create medium model for step function
# Re-run optimal model, includng Green_Certified Variable
gb_lm_full = lm(Rent ~ cluster_rent + age + Electricity_Costs + size + stories +
               class_a + amenities + CS_PropertyID + class_b + hd_total07 + net + 
               Gas_Costs + cluster + empl_gr + Precipitation + green_rating + cd_total_07 + 
               hd_total07 + total_dd_07 + LEED + Energystar + leasing_rate, data=gb_impute)
```

```{r bestmodel, include=TRUE}
gb_lm_step = step(gb_lm_full, 
                    scope=~(.)^2)
```

```{r othermodels, include=FALSE}
# AIC_gb_lm_step = 34662.54

# Variables Included in Regression
getCall(gb_lm_step)
coef(gb_lm_step)

# Lasso Model
# Full model
full = lm(Rent ~., data = gb_impute)
full

#Forward Stepwise Procedure
# Null Model
null = lm(Rent~1, data = gb_impute)

system.time(fwd <- step(null, scope = formula(full), dir="forward"))
# AIC_full = 35390.21

system.time(fwd <- step(null, scope = formula(gb_lm_forward), dir="forward"))
# AIC_gb_lm_forward_step = 34768.95

# Load gamlr for LASSO

# Create numeric design matrix
gbx = sparse.model.matrix(Rent ~., data = gb_impute)[,-1]

gby = gb_impute$Rent

# Fit single lasso
gb_lasso =  gamlr(gbx, gby)
plot(gb_lasso)

View(gb_lasso)

# AIC selected coef
AICc(gb_lasso)

# AIC_lasso= 35425.42

plot(gb_lasso$lambda, AICc(gb_lasso))
plot(log(gb_lasso$lambda), AICc(gb_lasso))

# Coefficient at AIC-optimizing value
gb_beta = coef(gb_lasso)
gb_beta

# Optimal lambda
log(gb_lasso$lambda[which.min(AICc(gb_lasso))])
sum(gb_beta!=0)

# CV lasso
gb_cvl = cv.gamlr(gbx, gby, verb = TRUE) 

# Plotting OOS deviance as a function of log lambda
plot(gb_cvl, bty="n") 

# CV min deviance Selection
gbb.min = coef(gb_cvl, select="min")
log(gb_cvl$lambda.min)
sum(gbb.min!=0)

# CV 1SE selection
gbb.1se = coef(gb_cvl)
log(gb_cvl$lambda.1se)
sum(gbb.1se!=0)

# Comparing AICc and CV error
plot(gb_cvl, bty="n")
lines(log(gb_lasso$lambda),AICc(gb_lasso)/n, col="green", lwd=2)
legend("top", fill=c("blue","green"),
       legend=c("CV","AICc"), bty="n")
#######

# Anova for model comparison
anova(full, gb_lm_forward, gb_lm_medium, gb_lm_step)

# Compared to the full model, all models findings are statistically significant at any level of significance
# We also find that the gb_lm_step model results not only in the lowest AIC, but also the lowest RSS and therefore is the optimal model 
# Best Performing Model: gb_lm_step
# AIC = 34662.54
# Variables:
getCall(gb_lm_step)

# Check model using Train-Test Split for comparison
set.seed(200)
index <- createDataPartition(gb_impute$Rent, p=.75, list = FALSE)

trainSet <- gb_impute[index,]

testSet <- gb_impute[-index,]

# checking for missing values
skim(trainSet) %>% skimr::kable()

# Normalize and Scale Variables
trainX <- trainSet[,-ncol(trainSet) != "Rent"]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues

# Training Data for knn
set.seed(200)
ctrl <- trainControl(method="repeatedcv", repeats = 5)
knnFit <- train(Rent ~., data = trainSet, method = "knn", trControl = ctrl, preProcess = c("center", "scale"), tuneLength = 20)

# knnFit outpit
knnFit

# Plotting knnFit results
plot(knnFit)

# Prediction of model
knnPredict <- predict(knnFit, newdata = testSet)

knnPredict

# KNN model gives an RMSE value of 9.872747 
sqrt(625851/7894)
# The RMSE for the optimal model, gb_lm_step, is 8.904036
```

```{r part2, include=TRUE}
coef(gb_lm_step)
```

```{r part3model, include=FALSE}
gbGR_lm_model = lm(formula = Rent ~ class_a:green_rating + class_b:green_rating + cluster_rent + age + Electricity_Costs + 
    size + stories + class_a + amenities + CS_PropertyID + class_b + 
    hd_total07 + net + Gas_Costs + cluster + empl_gr + Precipitation + 
    green_rating + cd_total_07 + LEED + leasing_rate + cluster_rent:size + 
    size:cluster + cluster_rent:cluster + size:Precipitation + 
    cluster_rent:stories + size:leasing_rate + net:cd_total_07 + 
    stories:class_a + age:class_b + age:class_a + hd_total07:Precipitation + 
    cluster_rent:LEED + stories:amenities + amenities:class_b + 
    cluster_rent:leasing_rate + class_b:Precipitation + size:cd_total_07 + 
    Electricity_Costs:class_b + Gas_Costs:Precipitation + cluster_rent:amenities + 
    amenities:green_rating + CS_PropertyID:hd_total07 + Electricity_Costs:CS_PropertyID + 
    CS_PropertyID:class_b + cluster_rent:age + age:Electricity_Costs + 
    cluster:leasing_rate + hd_total07:cd_total_07 + Electricity_Costs:cluster + 
    hd_total07:cluster + cluster_rent:cd_total_07 + class_a:Precipitation + 
    size:CS_PropertyID + amenities:CS_PropertyID + Electricity_Costs:class_a + 
    CS_PropertyID:empl_gr + amenities:Gas_Costs + amenities:Precipitation + 
    age:cd_total_07 + class_b:empl_gr + cluster_rent:net + stories:cluster + 
    class_a:CS_PropertyID + age:CS_PropertyID + LEED:leasing_rate + 
    class_a:Gas_Costs + class_b:Gas_Costs + CS_PropertyID:Gas_Costs + 
    Electricity_Costs:amenities + stories:cd_total_07 + class_a:empl_gr + 
    Gas_Costs:cluster + cluster:cd_total_07, data = gb_impute)
```

```{r part3, include=TRUE}
gbGR_lm_model
```

Problem 2
================
What causes what?
---------------- 
**1) Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime?**

The reason we can’t simply take data from multiple cities and run the regression of “Crime” on “Police” is due to the reverse causality problem that surrounds this regression. If we are trying to estimate the causal effect of the number of police officers in a city has on its crime rate, there is an issue of whether some cities have more police officers due to having a high crime rate, or if a city has a low crime rate because it has a high number of police officers. There is also an issue of potential lead-lag effects in regards to these variables. An immediate increase in the amount of police officers may not cause an immediate decrease in crime, or vis versa. Therefore, without using some sort of exogenous instrument that affects the number of police officers in a city, but does not affect the crime rate, we will be unable to find a causal estimate between them.

**2) How were the researchers from UPenn able to isolate this effect?**

Researchers at UPenn were able to isolate the effect that the number of police officers in a city has on its crime rate by using the “Terrorism Alert System”  as an instrumental variable. They found that when the system was placed at a terror alert level of orange in Washington D.C., the city increased the number of police officers it had patrolling the streets and in public places, and yet it would be highly unlikely that this terror alert would affect the number of crimes committed during this time period. Because of this, the terror alert level satisfied both criteria for being an instrumental variable since it was found to be correlated with the endogenous explanatory variable “Police”, since it caused an increase in the number of officers on the street, but was not correlated with the crime rate (due to this increase not being associated with the crime rate), or other factors in the explanatory equation such as the number of tourists in the city during this alert. By using this instrument, they found that the crime rate did in fact decrease during the time periods when the terrorism alert level was at orange, and thus when more cops were patrolling the streets. With this method, they were able to find that high alert days were correlated with a 7.316 unit decrease in the number of crimes committed, and a 6.046 unit decrease in the number of crimes committed during high alert days, when accounting for METRO ridership. Both of these estimates were statistically significant at the 5% level of significance. 

**3) Why did they have to control for Metro ridership? What was that trying to capture?**
  
The reason that the researchers controlled for Metro ridership is due to the fact that, if the number of metro riders in the city also decreased during high alert days, it is likely that the number of crimes that occurred in the city would decrease as well. By controlling for the effects of ridership on the number of crimes, they can show that, although high alert days decrease the crime rate in Washington D.C, its effect is not as high as when accounting for the number of tourists or citizens using the metro system in the city.

**4) What is the conclusion?**

This regression is estimating the effect that high alert days have on crime in different areas of D.C., with a focus on the National Mall (District 1). Separating D.C. into districts finds that, when the city is on high alert, there is a large decrease in the crime rate in District 1 of 13.679 units that is statistically significant at the 1% level, holding all else fixed, while there is only an 11.629 unit decrease in other districts during high alert days that is not statistically significant, holding all else fixed. This is likely due to the fact that large numbers of new police officers are stationed at the mall during high alert days due to it being a likely target for terroristic acts, and thus in need of more security. Due to this large increase in police officers, there is a strong, statistically significant, decrease in the crime rate during this time period that is not directly due to the crime rate of the area itself.


